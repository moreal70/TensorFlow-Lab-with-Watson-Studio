{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "---\n* *** \uc6d0\ubcf8 \uc18c\uc2a4\ub294 \ud64d\ucf69\uacfc\uae30\ub300 \uae40\uc131\ud6c8 \uad50\uc218\ub2d8\uc758  [Github link](https://github.com/hunkim/DeepLearningZeroToAll)\ub97c \ucc38\uc870\ud558\uc138\uc694 ***     \n* *** Watson studio notebook \uc5d0\uc11c \uc791\uc5c5 \uac00\ub2a5\ud558\ub3c4\ub85d \uc218\uc815\ud558\uc600\uc73c\uba70***\n* *** \ud55c\uae00\ub85c \uc124\uba85\ub41c \ubd80\ubd84\uc740 \uc81c\uac00 \uc2a4\ud130\ub514 \ud558\uba74\uc11c \uc774\ud574\ud55c \ub0b4\uc6a9\uc744 \ucd94\uac00\ud55c \uac83\uc785\ub2c8\ub2e4. ***\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## lab-11-5-mnist_cnn_ensemble_layers\n* ***\ubaa8\ub378\uc744 \uc5ec\ub7ec\uac1c \uc815\uc758\ud574\uc11c \uac01\uac01\uc758 \uacb0\uacfc \uac12\uc744 emsemble \ud558\ub294\ub370 \uc5ec\uae30\uc11c\ub294 \ub2e8\uc21c \ud569\uc0b0\uc744 \ud574\uc11c argmax \ucc98\ub9ac\ud568 ***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\nExtracting MNIST_data/train-images-idx3-ubyte.gz\nSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
                }
            ], 
            "source": "# Lab 11 MNIST and Deep learning CNN\n# https://www.tensorflow.org/tutorials/layers\nimport tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.examples.tutorials.mnist import input_data\n\ntf.set_random_seed(777)  # reproducibility\n\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n# more information about the mnist dataset\n\n# hyper parameters\nlearning_rate = 0.001\ntraining_epochs = 20\nbatch_size = 100"
        }, 
        {
            "source": "* ***Model class \uc815\uc758 ***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "class Model:\n\n    def __init__(self, sess, name):\n        self.sess = sess\n        self.name = name\n        self._build_net()\n\n    def _build_net(self):\n        with tf.variable_scope(self.name):\n            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1  for testing\n            self.training = tf.placeholder(tf.bool)\n\n            # input place holders\n            self.X = tf.placeholder(tf.float32, [None, 784])\n\n            # img 28x28x1 (black/white), Input Layer\n            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n            self.Y = tf.placeholder(tf.float32, [None, 10])\n\n            # Convolutional Layer #1 and Pooling Layer #1\n            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], padding=\"SAME\", strides=2)\n            dropout1 = tf.layers.dropout(inputs=pool1, rate=0.7, training=self.training)\n\n            # Convolutional Layer #2 and Pooling Layer #2\n            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], padding=\"SAME\", strides=2)\n            dropout2 = tf.layers.dropout(inputs=pool2, rate=0.7, training=self.training)\n\n            # Convolutional Layer #3 and Pooling Layer #3\n            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], padding=\"SAME\", strides=2)\n            dropout3 = tf.layers.dropout(inputs=pool3, rate=0.7, training=self.training)\n\n            # Dense Layer with Relu\n            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n            dense4 = tf.layers.dense(inputs=flat, units=625, activation=tf.nn.relu)\n            dropout4 = tf.layers.dropout(inputs=dense4, rate=0.5, training=self.training)\n\n            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n\n        # define cost/loss & optimizer\n        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n\n        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    def predict(self, x_test, training=False):\n        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.training: training})\n\n    def get_accuracy(self, x_test, y_test, training=False):\n        return self.sess.run(self.accuracy,  feed_dict={self.X: x_test, self.Y: y_test, self.training: training})\n\n    def train(self, x_data, y_data, training=True):\n        return self.sess.run([self.cost, self.optimizer], feed_dict={ self.X: x_data, self.Y: y_data, self.training: training})"
        }, 
        {
            "source": "* ***model \uc744 2\uac1c \uc120\uc5b8\ud558\uace0, Model class\ub97c \ubc18\ubcf5\ud574\uc11c \uc815\uc758 ***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# initialize\nsess = tf.Session()\n\nmodels = []\nnum_models = 2\nfor m in range(num_models):\n    models.append(Model(sess, \"model\" + str(m)))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Learning Started!\n"
                }
            ], 
            "source": "sess.run(tf.global_variables_initializer())\n\nprint('Learning Started!')\n\n# train my model\nfor epoch in range(training_epochs):\n    avg_cost_list = np.zeros(len(models))\n    total_batch = int(mnist.train.num_examples / batch_size)\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n\n        # train each model\n        for m_idx, m in enumerate(models):\n            c, _ = m.train(batch_xs, batch_ys)\n            avg_cost_list[m_idx] += c / total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n\nprint('Learning Finished!')"
        }, 
        {
            "source": "* ***\uac01 \ubaa8\ub378\uc758 p (\ud655\ub960)\uc744 \ub2e8\uc21c \ud569\uc0b0\ud574\uc11c prediction \ucd5c\uc885 \uac12\uc744 \uacc4\uc0b0\ud568***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Test model and check accuracy\ntest_size = len(mnist.test.labels)\npredictions = np.zeros(test_size * 10).reshape(test_size, 10)\n\nfor m_idx, m in enumerate(models):\n    print(m_idx, 'Accuracy:', m.get_accuracy(mnist.test.images, mnist.test.labels))\n    p = m.predict(mnist.test.images)\n    predictions += p"
        }, 
        {
            "source": "* ***prediction \uc5d0 argmax \ub97c \ud574\uc11c 0~9 \uae4c\uc9c0 \uc911\uc5d0\uc11c \uc81c\uc77c \ud070 \uac83\uc744 answer \ub85c \uc81c\uc2dc\ud568 ***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ensemble_correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\nensemble_accuracy = tf.reduce_mean(tf.cast(ensemble_correct_prediction, tf.float32))\nprint('Ensemble accuracy:', sess.run(ensemble_accuracy))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "'''\n0 Accuracy: 0.9933\n1 Accuracy: 0.9946\n2 Accuracy: 0.9934\n3 Accuracy: 0.9935\n4 Accuracy: 0.9935\n5 Accuracy: 0.9949\n6 Accuracy: 0.9941\n\nEnsemble accuracy: 0.9952\n'''"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}