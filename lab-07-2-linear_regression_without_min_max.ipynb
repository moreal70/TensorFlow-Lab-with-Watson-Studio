{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "---\n* *** \uc6d0\ubcf8 \uc18c\uc2a4\ub294 \ud64d\ucf69\uacfc\uae30\ub300 \uae40\uc131\ud6c8 \uad50\uc218\ub2d8\uc758  [Github link](https://github.com/hunkim/DeepLearningZeroToAll)\ub97c \ucc38\uc870\ud558\uc138\uc694 ***     \n* *** Watson studio notebook \uc5d0\uc11c \uc791\uc5c5 \uac00\ub2a5\ud558\ub3c4\ub85d \uc218\uc815\ud558\uc600\uc73c\uba70***\n* *** \ud55c\uae00\ub85c \uc124\uba85\ub41c \ubd80\ubd84\uc740 \uc81c\uac00 \uc2a4\ud130\ub514 \ud558\uba74\uc11c \uc774\ud574\ud55c \ub0b4\uc6a9\uc744 \ucd94\uac00\ud55c \uac83\uc785\ub2c8\ub2e4. ***\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Lab 7-2 Linear regression without min-max\n* ***\uc5ec\uae30\uc11c\ub294 feature (X) \ub4e4\uac04\uc758 data \ud06c\uae30 \ud3b8\ucc28\uac00 \ub108\ubb34 \ucee4\uc11c learning \uc774 \uc81c\ub300\ub85c \uc548\ub418\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4***\n* ***data \ud45c\uc900\ud654 \uc791\uc5c5\uc774 \ud544\uc694\ud569\ub2c8\ub2e4.   \uc138\ubc88\uc9f8 \uce7c\ub7fc \uac12\uc774 \uc0c1\ub300\uc801\uc73c\ub85c \ub108\ubb34 \ud07d\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import tensorflow as tf\nimport numpy as np\ntf.set_random_seed(777)  # for reproducibility\n\n\nxy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n               [816, 820.958984, 1008100, 815.48999, 819.23999],\n               [819.359985, 823, 1188100, 818.469971, 818.97998],\n               [819, 823, 1198100, 816, 820.450012],\n               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n\nx_data = xy[:, 0:-1]\ny_data = xy[:, [-1]]"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "DescribeResult(nobs=8, minmax=(array([8.09510010e+02, 8.15250000e+02, 9.08100000e+05, 8.04539978e+02]), array([8.28659973e+02, 8.33450012e+02, 1.82810000e+06, 8.28349976e+02])), mean=array([8.18397499e+02, 8.23098625e+02, 1.25810000e+06, 8.16658119e+02]), variance=array([3.71308274e+01, 3.44591661e+01, 8.51428571e+10, 5.23282265e+01]), skewness=array([ 0.11346773,  0.35788876,  0.80290717, -0.14738366]), kurtosis=array([-0.65064498, -0.57607135, -0.14880501, -0.42692814]))\nDescribeResult(nobs=8, minmax=(array([809.559998]), array([831.659973])), mean=array([820.7237395]), variance=array([52.15404165]), skewness=array([-0.00237535]), kurtosis=array([-0.87647491]))\n"
                }
            ], 
            "source": "from scipy import stats\nprint(stats.describe(x_data))\nprint(stats.describe(y_data))"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# placeholders for a tensor that will be always fed.\nX = tf.placeholder(tf.float32, shape=[None, 4])\nY = tf.placeholder(tf.float32, shape=[None, 1])\n\nW = tf.Variable(tf.random_normal([4, 1]), name='weight')\nb = tf.Variable(tf.random_normal([1]), name='bias')\n\n# Hypothesis\nhypothesis = tf.matmul(X, W) + b\n\n# Simplified cost/loss function\ncost = tf.reduce_mean(tf.square(hypothesis - Y))\n\n# Minimize\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-10)\ntrain = optimizer.minimize(cost)"
        }, 
        {
            "source": "* ***\ud639\uc2dc\ub098 \ud574\uc11c Learning rate \ub97c \uc870\uc815\ud574\ubcf4\uc9c0\ub9cc \uacb0\uacfc\ub294 \ub3d9\uc77c\ud558\ub124\uc694***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Cost:  5940297000000.0\n5 Cost:  inf\n10 Cost:  inf\n15 Cost:  nan\n20 Cost:  nan\n25 Cost:  nan\n30 Cost:  nan\n35 Cost:  nan\n40 Cost:  nan\n45 Cost:  nan\n50 Cost:  nan\n55 Cost:  nan\n60 Cost:  nan\n65 Cost:  nan\n70 Cost:  nan\n75 Cost:  nan\n80 Cost:  nan\n85 Cost:  nan\n90 Cost:  nan\n95 Cost:  nan\n100 Cost:  nan\nPrediction ---\n [[nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]\n [nan]]\n"
                }
            ], 
            "source": "# Launch the graph in a session.\nsess = tf.Session()\n# Initializes global variables in the graph.\nsess.run(tf.global_variables_initializer())\n\nfor step in range(101):\n    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n    if step % 5 == 0:\n        print(step, \"Cost: \", cost_val)\nprint(\"Prediction ---\\n\", hy_val)"
        }, 
        {
            "source": "* ***cost \uac12\uc774 \ubb34\ud55c\ub300\ub85c \ubc1c\uc0b0\ud574\ubc84\ub9bd\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "'''\n0 Cost:  2.45533e+12\nPrediction:\n [[-1104436.375]\n [-2224342.75 ]\n [-1749606.75 ]\n [-1226179.375]\n [-1445287.125]\n [-1457459.5  ]\n [-1335740.5  ]\n [-1700924.625]]\n1 Cost:  2.69762e+27\nPrediction:\n [[  3.66371490e+13]\n [  7.37543360e+13]\n [  5.80198785e+13]\n [  4.06716290e+13]\n [  4.79336847e+13]\n [  4.83371348e+13]\n [  4.43026590e+13]\n [  5.64060907e+13]]\n2 Cost:  inf\nPrediction:\n [[ -1.21438790e+21]\n [ -2.44468702e+21]\n [ -1.92314724e+21]\n [ -1.34811610e+21]\n [ -1.58882674e+21]\n [ -1.60219962e+21]\n [ -1.46847142e+21]\n [ -1.86965602e+21]]\n3 Cost:  inf\nPrediction:\n [[  4.02525216e+28]\n [  8.10324465e+28]\n [  6.37453079e+28]\n [  4.46851237e+28]\n [  5.26638074e+28]\n [  5.31070676e+28]\n [  4.86744608e+28]\n [  6.19722623e+28]]\n4 Cost:  inf\nPrediction:\n [[ -1.33422428e+36]\n [ -2.68593010e+36]\n [ -2.11292430e+36]\n [ -1.48114879e+36]\n [ -1.74561303e+36]\n [ -1.76030542e+36]\n [ -1.61338091e+36]\n [ -2.05415459e+36]]\n5 Cost:  inf\nPrediction:\n [[ inf]\n [ inf]\n [ inf]\n [ inf]\n [ inf]\n [ inf]\n [ inf]\n [ inf]]\n6 Cost:  nan\nPrediction:\n [[ nan]\n [ nan]\n [ nan]\n [ nan]\n [ nan]\n [ nan]\n [ nan]\n [ nan]]\n'''"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}