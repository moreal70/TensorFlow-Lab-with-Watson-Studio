{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "---\n* *** \uc6d0\ubcf8 \uc18c\uc2a4\ub294 \ud64d\ucf69\uacfc\uae30\ub300 \uae40\uc131\ud6c8 \uad50\uc218\ub2d8\uc758  [Github link](https://github.com/hunkim/DeepLearningZeroToAll)\ub97c \ucc38\uc870\ud558\uc138\uc694 ***     \n* *** Watson studio notebook \uc5d0\uc11c \uc791\uc5c5 \uac00\ub2a5\ud558\ub3c4\ub85d \uc218\uc815\ud558\uc600\uc73c\uba70***\n* *** \ud55c\uae00\ub85c \uc124\uba85\ub41c \ubd80\ubd84\uc740 \uc81c\uac00 \uc2a4\ud130\ub514 \ud558\uba74\uc11c \uc774\ud574\ud55c \ub0b4\uc6a9\uc744 \ucd94\uac00\ud55c \uac83\uc785\ub2c8\ub2e4. ***\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Lab 7 Learning rate and Evaluation\n* ***\uc774\ubc88 Lab \uc5d0\uc11c\ub294 learning rate \ub97c \ub2e4\uc591\ud558\uac8c \ubcc0\ud654\uc2dc\ud0a4 \uac00\uba74\uc11c \uadf8 \uc758\ubbf8\ub97c \ud30c\uc545\ud569\ub2c8\ub2e4.***\n* ***\ub108\ubb34 \uc791\uc73c\uba74, \uc131\ub2a5\uc5d0 \ubb38\uc81c\uac00 \ub420\uc218 \uc788\uace0, \ub108\ubb34 \ud06c\uba74 \ucd5c\uc18c\uac12\uc73c\ub85c gradient descent \ud558\uc9c0 \uc54a\uace0, \ubc1c\uc0b0\ud574 \ubc84\ub9b4 \uac00\ub2a5\uc131\uc774 \uc788\uc2b5\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import tensorflow as tf\ntf.set_random_seed(777)  # for reproducibility\n\nx_data = [[1, 2, 1],\n          [1, 3, 2],\n          [1, 3, 4],\n          [1, 5, 5],\n          [1, 7, 5],\n          [1, 2, 5],\n          [1, 6, 6],\n          [1, 7, 7]]\ny_data = [[0, 0, 1],\n          [0, 0, 1],\n          [0, 0, 1],\n          [0, 1, 0],\n          [0, 1, 0],\n          [0, 1, 0],\n          [1, 0, 0],\n          [1, 0, 0]]\n\n\n# Evaluation our model using this test dataset\nx_test = [[2, 1, 1],\n          [3, 1, 2],\n          [3, 3, 4]]\ny_test = [[0, 0, 1],\n          [0, 0, 1],\n          [0, 0, 1]]\n\nX = tf.placeholder(\"float\", [None, 3])\nY = tf.placeholder(\"float\", [None, 3])\n\nW = tf.Variable(tf.random_normal([3, 3]))\nb = tf.Variable(tf.random_normal([3]))"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# tf.nn.softmax computes softmax activations\n# softmax = exp(logits) / reduce_sum(exp(logits), dim)\nhypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n\n# Cross entropy cost/loss\ncost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n# Try to change learning_rate to small numbers"
        }, 
        {
            "source": "* ***l_rate \ub97c \ub2e4\uc591\ud558\uac8c \ubcc0\ud654\uc2dc\ucf1c\uc11c \ub2e4\uc2dc \ub3cc\ub9bd\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "WARNING:tensorflow:From <ipython-input-3-cf77d44aa4cc>:5: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `argmax` instead\n"
                }
            ], 
            "source": "l_rate = 0.01\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=l_rate).minimize(cost)\n\n# Correct prediction Test model\nprediction = tf.arg_max(hypothesis, 1)\nis_correct = tf.equal(prediction, tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 --- 5.73203\n100 --- 1.82629\n200 --- 1.66071\n300 --- 1.52343\n400 --- 1.40755\n500 --- 1.30743\n600 --- 1.21942\n700 --- 1.14131\n800 --- 1.0717\n900 --- 1.00967\n1000 --- 0.954545\n"
                }
            ], 
            "source": "# Launch graph\nsess = tf.Session()\n# Initialize TensorFlow variables\nsess.run(tf.global_variables_initializer())\n\nfor step in range(1001):\n    cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n    if (step % 100 == 0):\n        print(step,'---',cost_val) "
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Prediction: [1 1 1]\nAccuracy:  0.0\n"
                }
            ], 
            "source": "# predict\nprint(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n# Calculate the accuracy\nprint(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "'''\nwhen lr = 1.5\n0 5.73203 [[-0.30548954  1.22985029 -0.66033536]\n [-4.39069986  2.29670858  2.99386835]\n [-3.34510708  2.09743214 -0.80419564]]\n1 23.1494 [[ 0.06951046  0.29449689 -0.0999819 ]\n [-1.95319986 -1.63627958  4.48935604]\n [-0.90760708 -1.65020132  0.50593793]]\n2 27.2798 [[ 0.44451016  0.85699677 -1.03748143]\n [ 0.48429942  0.98872018 -0.57314301]\n [ 1.52989244  1.16229868 -4.74406147]]\n3 8.668 [[ 0.12396193  0.61504567 -0.47498202]\n [ 0.22003263 -0.2470119   0.9268558 ]\n [ 0.96035379  0.41933775 -3.43156195]]\n4 5.77111 [[-0.9524312   1.13037777  0.08607888]\n [-3.78651619  2.26245379  2.42393875]\n [-3.07170963  3.14037919 -2.12054014]]\n5 inf [[ nan  nan  nan]\n [ nan  nan  nan]\n [ nan  nan  nan]]\n6 nan [[ nan  nan  nan]\n [ nan  nan  nan]\n [ nan  nan  nan]]\n\n ...\nPrediction: [0 0 0]\nAccuracy:  0.0\n\n-------------------------------------------------\nWhen lr = 1e-10\n0 5.73203 [[ 0.80269563  0.67861295 -1.21728313]\n [-0.3051686  -0.3032113   1.50825703]\n [ 0.75722361 -0.7008909  -2.10820389]]\n1 5.73203 [[ 0.80269563  0.67861295 -1.21728313]\n [-0.3051686  -0.3032113   1.50825703]\n [ 0.75722361 -0.7008909  -2.10820389]]\n2 5.73203 [[ 0.80269563  0.67861295 -1.21728313]\n [-0.3051686  -0.3032113   1.50825703]\n [ 0.75722361 -0.7008909  -2.10820389]]\n...\n\n198 5.73203 [[ 0.80269563  0.67861295 -1.21728313]\n [-0.3051686  -0.3032113   1.50825703]\n [ 0.75722361 -0.7008909  -2.10820389]]\n199 5.73203 [[ 0.80269563  0.67861295 -1.21728313]\n [-0.3051686  -0.3032113   1.50825703]\n [ 0.75722361 -0.7008909  -2.10820389]]\n200 5.73203 [[ 0.80269563  0.67861295 -1.21728313]\n [-0.3051686  -0.3032113   1.50825703]\n [ 0.75722361 -0.7008909  -2.10820389]]\nPrediction: [0 0 0]\nAccuracy:  0.0\n-------------------------------------------------\nWhen lr = 0.1\n\n0 5.73203 [[ 0.72881663  0.71536207 -1.18015325]\n [-0.57753736 -0.12988332  1.60729778]\n [ 0.48373488 -0.51433605 -2.02127004]]\n1 3.318 [[ 0.66219079  0.74796319 -1.14612854]\n [-0.81948912  0.03000021  1.68936598]\n [ 0.23214608 -0.33772916 -1.94628811]]\n2 2.0218 [[ 0.64342022  0.74127686 -1.12067163]\n [-0.81161296 -0.00900121  1.72049117]\n [ 0.2086665  -0.35079569 -1.909742  ]]\n\n...\n\n199 0.672261 [[-1.15377033  0.28146935  1.13632679]\n [ 0.37484586  0.18958236  0.33544877]\n [-0.35609841 -0.43973011 -1.25604188]]\n200 0.670909 [[-1.15885413  0.28058422  1.14229572]\n [ 0.37609792  0.19073224  0.33304682]\n [-0.35536593 -0.44033223 -1.2561723 ]]\nPrediction: [2 2 2]\nAccuracy:  1.0\n'''"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}