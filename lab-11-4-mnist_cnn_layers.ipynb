{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "---\n* *** \uc6d0\ubcf8 \uc18c\uc2a4\ub294 \ud64d\ucf69\uacfc\uae30\ub300 \uae40\uc131\ud6c8 \uad50\uc218\ub2d8\uc758  [Github link](https://github.com/hunkim/DeepLearningZeroToAll)\ub97c \ucc38\uc870\ud558\uc138\uc694 ***     \n* *** Watson studio notebook \uc5d0\uc11c \uc791\uc5c5 \uac00\ub2a5\ud558\ub3c4\ub85d \uc218\uc815\ud558\uc600\uc73c\uba70***\n* *** \ud55c\uae00\ub85c \uc124\uba85\ub41c \ubd80\ubd84\uc740 \uc81c\uac00 \uc2a4\ud130\ub514 \ud558\uba74\uc11c \uc774\ud574\ud55c \ub0b4\uc6a9\uc744 \ucd94\uac00\ud55c \uac83\uc785\ub2c8\ub2e4. ***\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## lab-11-4-mnist_cnn_layers\n* ***11-3\ud558\uace0 \ub3d9\uc77c\ud55c \uad6c\uc870\uc9c0\ub9cc, tf.layers \uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \ud568\uc218\ub97c \uc0ac\uc6a9 ***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Extracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
                }
            ], 
            "source": "# Lab 11 MNIST and Deep learning CNN\nimport tensorflow as tf\n# import matplotlib.pyplot as plt\n\nfrom tensorflow.examples.tutorials.mnist import input_data\n\ntf.set_random_seed(777)  # reproducibility\n\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n# more information about the mnist dataset\n\n# hyper parameters\nlearning_rate = 0.001\ntraining_epochs = 15\nbatch_size = 100"
        }, 
        {
            "source": "* *** tf.layers \uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uba74 filter\uc758 \uac2f\uc218, padding \uc635\uc158, pool \uc0ac\uc774\uc988, dropout rate \ub4f1\uc744 \uc9c0\uc815\ud558\uae30\ub9cc \ud558\uba74 \ub428***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "IndentationError", 
                    "evalue": "unindent does not match any outer indentation level (<tokenize>, line 52)", 
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m52\u001b[0m\n\u001b[0;31m    self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "class Model:\n\n    def __init__(self, sess, name):\n        self.sess = sess\n        self.name = name\n        self._build_net()\n\n    def _build_net(self):\n        with tf.variable_scope(self.name):\n            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n            # for testing\n            self.training = tf.placeholder(tf.bool)\n\n            # input place holders\n            self.X = tf.placeholder(tf.float32, [None, 784])\n\n            # img 28x28x1 (black/white), Input Layer\n            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n            self.Y = tf.placeholder(tf.float32, [None, 10])\n\n            # Convolutional Layer #1, # Pooling Layer #1\n            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], padding=\"SAME\", strides=2)\n            dropout1 = tf.layers.dropout(inputs=pool1, rate=0.7, training=self.training)\n'''\n            # \uc704\uc5d0 3\uc904\ub85c \uc544\ub798 \ub77c\uc778\ub4e4\uc774 \ub300\uccb4 \ub428,,\uc9c1\uad00\uc131\uc744 \ub192\uc77c\uc218 \uc788\uc74c\n            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n            L1 = tf.nn.relu(L1)\n            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n'''            \n            # Convolutional Layer #2 and Pooling Layer #2\n            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], padding=\"SAME\", strides=2)\n            dropout2 = tf.layers.dropout(inputs=pool2, rate=0.7, training=self.training)\n\n            # Convolutional Layer #2 and Pooling Layer #2\n            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu)\n            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], padding=\"same\", strides=2)\n            dropout3 = tf.layers.dropout(inputs=pool3, rate=0.7, training=self.training)\n\n            # Dense Layer with Relu\n            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n            dense4 = tf.layers.dense(inputs=flat, units=625, activation=tf.nn.relu)\n            dropout4 = tf.layers.dropout(inputs=dense4, rate=0.5, training=self.training)\n\n            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n\n        # define cost/loss & optimizer\n        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n\n        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    def predict(self, x_test, training=False):\n        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.training: training})\n\n    def get_accuracy(self, x_test, y_test, training=False):\n        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.training: training})\n\n    def train(self, x_data, y_data, training=True):\n        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: x_data, self.Y: y_data, self.training: training})"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# initialize\nsess = tf.Session()\nm1 = Model(sess, \"m1\")\n\nsess.run(tf.global_variables_initializer())\n\nprint('Learning Started!')\n\n# train my model\nfor epoch in range(training_epochs):\n    avg_cost = 0\n    total_batch = int(mnist.train.num_examples / batch_size)\n\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        c, _ = m1.train(batch_xs, batch_ys)\n        avg_cost += c / total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n\nprint('Learning Finished!')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Test model and check accuracy\nprint('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}