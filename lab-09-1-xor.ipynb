{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "---\n* *** \uc6d0\ubcf8 \uc18c\uc2a4\ub294 \ud64d\ucf69\uacfc\uae30\ub300 \uae40\uc131\ud6c8 \uad50\uc218\ub2d8\uc758  [Github link](https://github.com/hunkim/DeepLearningZeroToAll)\ub97c \ucc38\uc870\ud558\uc138\uc694 ***     \n* *** Watson studio notebook \uc5d0\uc11c \uc791\uc5c5 \uac00\ub2a5\ud558\ub3c4\ub85d \uc218\uc815\ud558\uc600\uc73c\uba70***\n* *** \ud55c\uae00\ub85c \uc124\uba85\ub41c \ubd80\ubd84\uc740 \uc81c\uac00 \uc2a4\ud130\ub514 \ud558\uba74\uc11c \uc774\ud574\ud55c \ub0b4\uc6a9\uc744 \ucd94\uac00\ud55c \uac83\uc785\ub2c8\ub2e4. ***\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Lab 9 XOR\n* ***\uc774\ubc88 Lab \uc740 xor \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub294 \uc2dc\ub3c4\uc774\uba70,  x, y data \ub97c \ubcf4\uba74, xor \ub77c\ub294 \uac83\uc744 \uc54c\uc218 \uc788\uc2b5\ub2c8\ub2e4.***\n* ***\uc0ac\uc2e4\uc0c1 \ub2f5\uc744 \uc815\ud655\ud558\uac8c \uad6c\ud558\uc9c0 \ubabb\ud569\ub2c8\ub2e4.***\n* ***\uc774 xor \ubb38\uc81c\ub294 machine learning history \uc5d0\uc11c neural network \uc744 \ud1b5\ud574\uc11c \ud574\uacb0\ub429\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Lab 9 XOR\nimport tensorflow as tf\nimport numpy as np\n\ntf.set_random_seed(777)  # for reproducibility\nlearning_rate = 0.01\n\nx_data = [[0, 0],\n          [0, 1],\n          [1, 0],\n          [1, 1]]\ny_data = [[0],\n          [1],\n          [1],\n          [0]]\nx_data = np.array(x_data, dtype=np.float32)\ny_data = np.array(y_data, dtype=np.float32)"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "X = tf.placeholder(tf.float32, [None, 2])\nY = tf.placeholder(tf.float32, [None, 1])\n\nW = tf.Variable(tf.random_normal([2, 1]), name='weight')\nb = tf.Variable(tf.random_normal([1]), name='bias')\n\n# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\nhypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n\n# cost/loss function\ncost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n\ntrain = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Accuracy computation\n# True if hypothesis>0.5 else False\npredicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\naccuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 ---- 0.835191\n1000 ---- 0.751043\n2000 ---- 0.716555\n3000 ---- 0.702826\n4000 ---- 0.697257\n5000 ---- 0.694931\n6000 ---- 0.693934\n7000 ---- 0.693498\n8000 ---- 0.693305\n9000 ---- 0.693219\n10000 ---- 0.69318\n[[ 0.02417218]\n [ 0.0196571 ]]\n"
                }
            ], 
            "source": "# Launch graph\nsess = tf.Session()\n# Initialize TensorFlow variables\nsess.run(tf.global_variables_initializer())\n\nfor step in range(10001):\n    sess.run(train, feed_dict={X: x_data, Y: y_data})\n    if step % 1000 == 0:\n       print(step,'----', sess.run(cost, feed_dict={X: x_data, Y: y_data}))\nprint(sess.run(W))"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\nHypothesis:  [[ 0.49350187]\n [ 0.4984158 ]\n [ 0.49954456]\n [ 0.50445873]] \nCorrect:  [[ 0.]\n [ 0.]\n [ 0.]\n [ 1.]] \nAccuracy:  0.25\n"
                }
            ], 
            "source": "# Accuracy report\nh, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\nprint(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
        }, 
        {
            "source": "* ***Learning rate\ub97c \ubc14\uafd4\uac00\uba74\uc11c \ub3cc\ub824\ubcf4\ub354\ub77c\ub3c4,  accuracy\uac00 1\uc774 \uc548\ub429\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "'''\nHypothesis:  [[ 0.5]\n [ 0.5]\n [ 0.5]\n [ 0.5]]\nCorrect:  [[ 0.]\n [ 0.]\n [ 0.]\n [ 0.]]\nAccuracy:  0.5\n'''"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}