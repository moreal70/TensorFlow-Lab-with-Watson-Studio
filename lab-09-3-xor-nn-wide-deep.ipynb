{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "---\n* *** \uc6d0\ubcf8 \uc18c\uc2a4\ub294 \ud64d\ucf69\uacfc\uae30\ub300 \uae40\uc131\ud6c8 \uad50\uc218\ub2d8\uc758  [Github link](https://github.com/hunkim/DeepLearningZeroToAll)\ub97c \ucc38\uc870\ud558\uc138\uc694 ***     \n* *** Watson studio notebook \uc5d0\uc11c \uc791\uc5c5 \uac00\ub2a5\ud558\ub3c4\ub85d \uc218\uc815\ud558\uc600\uc73c\uba70***\n* *** \ud55c\uae00\ub85c \uc124\uba85\ub41c \ubd80\ubd84\uc740 \uc81c\uac00 \uc2a4\ud130\ub514 \ud558\uba74\uc11c \uc774\ud574\ud55c \ub0b4\uc6a9\uc744 \ucd94\uac00\ud55c \uac83\uc785\ub2c8\ub2e4. ***\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Lab 9-3 XOR deep learning\n* ***layer\ub97c \uc5ec\ub7ec\uce35 \ub450\uc5b4\uc11c deep learning \uac1c\ub150\uc73c\ub85c \uc811\uadfc\ud587\uc2b5\ub2c8\ub2e4.***\n* ***\uc989 layer \ub294 4\uac1c\ub85c \ud655\uc7a5 \ud588\uace0(deep) , output \uc758 \uac2f\uc218\ub3c4 10\uac1c\ub85c (wide) \ub298\ub838\uc2b5\ub2c8\ub2e4. ***\n* ***xor \uacb0\uacfc \uc608\uce21\uc740 \uc815\ud655\ud558\uac8c \ud569\ub2c8\ub2e4. ***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import tensorflow as tf\nimport numpy as np\n\ntf.set_random_seed(777)  # for reproducibility\nlearning_rate = 0.1\n\nx_data = [[0, 0],\n          [0, 1],\n          [1, 0],\n          [1, 1]]\ny_data = [[0],\n          [1],\n          [1],\n          [0]]\nx_data = np.array(x_data, dtype=np.float32)\ny_data = np.array(y_data, dtype=np.float32)\n\nX = tf.placeholder(tf.float32, [None, 2])\nY = tf.placeholder(tf.float32, [None, 1])"
        }, 
        {
            "source": "* ***4\ubc88\uc758 learning \uacfc\uc815\uc744 \uac70\uce69\ub2c8\ub2e4.***\n* ***[2.10] \uc5d0\uc11c \ubcf4\uc2dc\ub294 \ubc14\uc640 \uac19\uc774 10\uac1c\uc758 output \uc774 \ub098\uc635\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\nb1 = tf.Variable(tf.random_normal([10]), name='bias1')\nlayer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n\nW2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')\nb2 = tf.Variable(tf.random_normal([10]), name='bias2')\nlayer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n\nW3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')\nb3 = tf.Variable(tf.random_normal([10]), name='bias3')\nlayer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n\nW4 = tf.Variable(tf.random_normal([10, 1]), name='weight4')\nb4 = tf.Variable(tf.random_normal([1]), name='bias4')\nhypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)"
        }, 
        {
            "source": "* ***\ub098\uba38\uc9c0 \uc544\ub798 \ucf54\ub4dc\ub294 \uc55e\uc5d0 lab \uacfc \ub3d9\uc77c\ud569\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# cost/loss function\ncost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n\ntrain = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Accuracy computation\n# True if hypothesis>0.5 else False\npredicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\naccuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 0.84712\n1000 0.675448\n2000 0.358474\n3000 0.0370482\n4000 0.0152862\n5000 0.00920021\n6000 0.00645991\n7000 0.00492872\n8000 0.00396027\n9000 0.00329654\n10000 0.00281518\nw1--- [[ 1.48894799  0.5858897  -1.273965    1.85467267  3.29194474 -0.74085188\n  -2.65020895 -1.03821683  0.98222762 -1.92386103]\n [ 0.86843085 -1.78178215 -2.89059925  1.51849186 -0.49770623  0.08182307\n  -2.69622731 -0.3621999   2.197438   -0.89892793]]\nw2--- [[ 0.19393426 -0.19376647 -0.97276056 -1.23914552 -0.63106394 -1.71684754\n  -0.76176125 -0.4416596   1.21370721  1.32344759]\n [-1.57002866  0.06560797 -1.28646183  0.76344526  0.71697444  0.56040084\n   0.43546167  0.76401669  0.57215494  0.62079412]\n [-0.75010645  0.88316989 -3.96111107  1.69811511  1.70593941 -1.89934921\n   0.21306324  1.05737233 -0.36168459 -2.70598865]\n [-1.7414124  -1.46264935  2.49804807  0.60324907  1.04684412  0.66252416\n  -1.80761731 -1.05318654  2.68560314  2.48085093]\n [ 1.2740227   0.26582184  1.38237846  3.14028382  3.18876648 -1.55015635\n   0.2413415  -0.79185063 -0.08082     1.64970827]\n [-0.03384218 -0.9914062  -0.2114418  -0.08458405  0.10720655  1.5092485\n  -1.46577632 -0.0351711  -0.32184348 -0.46293119]\n [ 2.46375346 -0.6212917  -1.56429696 -0.97177541  1.43233263  0.6999625\n  -1.6775552  -0.73286277 -0.09047192 -4.18146896]\n [-0.04342251  0.17962047 -0.00819965  2.14876699 -0.47879732 -0.11204045\n   0.67245805 -0.49144691  0.04508103 -1.35557723]\n [ 0.02850632  0.17127419  2.17938089  0.36657366 -1.08799493  0.28749624\n  -0.75670892 -0.29826418  0.26909754  2.5537107 ]\n [ 0.18493348  1.04504561 -2.47649646  0.46631896 -0.73562229 -1.67022538\n  -0.72648966 -0.07220723  0.25399771 -2.19432855]]\nw3--- [[  4.81381148e-01   3.38543057e-01  -8.72041523e-01  -3.26413333e-01\n   -5.68677112e-02   2.70246327e-01  -9.63688970e-01   6.53095007e-01\n   -8.12388659e-01   1.18739569e+00]\n [ -5.88130057e-01   5.14939576e-02   1.36586102e-02   1.81418920e+00\n    1.95410132e-01   1.28968537e+00   1.08044553e+00   1.22771777e-01\n   -1.16616331e-01  -2.55367446e+00]\n [ -3.84043843e-01   2.38769233e-01   1.57073021e+00  -2.76520878e-01\n    6.95463941e-02  -2.21541357e+00   1.16092540e-01   5.29012346e+00\n   -2.88529468e+00   2.14596677e+00]\n [ -2.19977903e+00  -4.15984690e-01   1.68027073e-01  -6.00045681e-01\n   -2.42902231e+00  -3.47560272e-02   8.67401779e-01   1.24552524e+00\n    1.75572240e+00   3.03952284e-02]\n [  7.69380808e-01   5.94305098e-01  -1.60101366e+00  -5.30132949e-01\n   -2.35453129e+00  -9.10743773e-01   1.43066537e+00   1.56547093e+00\n   -1.40039957e+00  -1.29346395e+00]\n [ -9.05525029e-01  -5.29694617e-01  -8.81194830e-01   8.14495146e-01\n    1.86933303e+00   1.71352670e-01   1.46754324e+00   4.91290510e-01\n    1.06204402e+00   9.17752385e-01]\n [  4.42802235e-02   6.01209998e-01   1.38117778e+00   9.80782090e-04\n   -2.20924067e+00  -1.13469708e+00  -1.28898537e+00  -2.04371400e-02\n    5.55121064e-01  -1.35250032e+00]\n [  1.37312949e-01  -1.30333865e+00   1.13222703e-01  -9.88038421e-01\n   -8.33063543e-01   2.28799060e-01   1.26321483e+00  -6.57214522e-01\n    1.40680283e-01  -1.06955075e+00]\n [ -1.92351699e+00  -3.29802930e-01   7.38687396e-01  -1.16991192e-01\n    9.31507289e-01  -2.43823457e+00  -7.69890547e-01  -2.60387540e-01\n   -3.89181562e-02   1.41332901e+00]\n [ -9.64443445e-01   9.06687498e-01   4.07479906e+00  -9.62142497e-02\n    3.59087765e-01   2.57377577e+00   6.01330519e-01  -4.70885515e+00\n    7.13007152e-01   6.35568619e-01]]\nw4--- [[ 0.90470672]\n [-0.40556386]\n [ 3.78914833]\n [ 0.03659722]\n [ 0.74987918]\n [ 3.62820244]\n [-1.31306887]\n [-8.77655506]\n [ 2.72241354]\n [-2.24215031]]\n"
                }
            ], 
            "source": "# Launch graph\nsess = tf.Session()\n# Initialize TensorFlow variables\nsess.run(tf.global_variables_initializer())\n\nfor step in range(10001):\n    sess.run(train, feed_dict={X: x_data, Y: y_data})\n    if step % 1000 == 0:\n        print(step, sess.run(cost, feed_dict={ X: x_data, Y: y_data}))\nprint('w1---',sess.run(W1))\nprint('w2---',sess.run(W2))\nprint('w3---',sess.run(W3))\nprint('w4---',sess.run(W4))"
        }, 
        {
            "source": "* ***cost \uac12\uc774 0 \uc73c\ub85c \uc218\ub834\ud558\ub294 \uc18d\ub3c4\uac00 layer 2 \ubcf4\ub2e4 \ud6e8\uc52c \ube60\ub985\ub2c8\ub2e4.(\uc55e\uc5d0 lab\uc758 \uacb0\uacfc\ud558\uace0 \ube44\uad50)***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\nHypothesis:---  [[ 0.00254145]\n [ 0.99812061]\n [ 0.99639231]\n [ 0.00321545]] \nCorrect: --- [[ 0.]\n [ 1.]\n [ 1.]\n [ 0.]] \nAccuracy:---  1.0\n"
                }
            ], 
            "source": "# Accuracy report\nh, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\nprint(\"\\nHypothesis:--- \", h, \"\\nCorrect: ---\", c, \"\\nAccuracy:--- \", a)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "'''\nHypothesis:  [[ 0.01338218]\n [ 0.98166394]\n [ 0.98809403]\n [ 0.01135799]]\nCorrect:  [[ 0.]\n [ 1.]\n [ 1.]\n [ 0.]]\nAccuracy:  1.0\n'''"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}