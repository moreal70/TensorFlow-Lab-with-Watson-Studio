{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "---\n* *** \uc6d0\ubcf8 \uc18c\uc2a4\ub294 \ud64d\ucf69\uacfc\uae30\ub300 \uae40\uc131\ud6c8 \uad50\uc218\ub2d8\uc758  [Github link](https://github.com/hunkim/DeepLearningZeroToAll)\ub97c \ucc38\uc870\ud558\uc138\uc694 ***     \n* *** Watson studio notebook \uc5d0\uc11c \uc791\uc5c5 \uac00\ub2a5\ud558\ub3c4\ub85d \uc218\uc815\ud558\uc600\uc73c\uba70***\n* *** \ud55c\uae00\ub85c \uc124\uba85\ub41c \ubd80\ubd84\uc740 \uc81c\uac00 \uc2a4\ud130\ub514 \ud558\uba74\uc11c \uc774\ud574\ud55c \ub0b4\uc6a9\uc744 \ucd94\uac00\ud55c \uac83\uc785\ub2c8\ub2e4. ***\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Lab 4 Multi-variable linear regression", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "* ***\uc774\ubc88 Lab \uc5d0\uc11c\ub294 multi-variable \uc989 feature \uac00 \uc5ec\ub7ec\uac1c\uc778 \uacbd\uc6b0 \uc785\ub2c8\ub2e4.***\n* ***x1,x2,x3 --> column \uc774\ub77c\uace0 \uc0dd\uac01\ud558\uba74 \ub428***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import tensorflow as tf\ntf.set_random_seed(777)  # for reproducibility\n\nx1_data = [73., 93., 89., 96., 73.]\nx2_data = [80., 88., 91., 98., 66.]\nx3_data = [75., 93., 90., 100., 70.]\n\ny_data = [152., 185., 180., 196., 142.]"
        }, 
        {
            "source": "* ***\uac01\uac01\uc758 feature \ubcc4\ub85c w1, w2, w3 \ub97c \uc815\uc758\ud574\uc57c \uaca0\uc9c0\uc694***\n* ***hypothesis \uac00  \uc55e\uc5d0\uc11c\ub294 1\ud56d \uc774\uc5c8\ub294\ub370, \uc5ec\uae30\uc11c\ub294 3\ud56d\uc774 \ub418\uc5c8\uc2b5\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Tensor(\"add_2:0\", dtype=float32)\n"
                }
            ], 
            "source": "# placeholders for a tensor that will be always fed.\nx1 = tf.placeholder(tf.float32)\nx2 = tf.placeholder(tf.float32)\nx3 = tf.placeholder(tf.float32)\n\nY = tf.placeholder(tf.float32)\n\nw1 = tf.Variable(tf.random_normal([1]), name='weight1')\nw2 = tf.Variable(tf.random_normal([1]), name='weight2')\nw3 = tf.Variable(tf.random_normal([1]), name='weight3')\nb = tf.Variable(tf.random_normal([1]), name='bias')\n\nhypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\nprint(hypothesis)"
        }, 
        {
            "source": "* ***\ub098\uba38\uc9c0\ub294 \uc18c\uc2a4 \ucf54\ub4dc \uc790\uccb4\uac00 \ub611\uac19\uc2b5\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# cost/loss function\ncost = tf.reduce_mean(tf.square(hypothesis - Y))\n\n# Minimize. Need a very small learning rate for this data set\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\ntrain = optimizer.minimize(cost)\n\n#%%\n# Launch the graph in a session.\nsess = tf.Session()\n# Initializes global variables in the graph.\nsess.run(tf.global_variables_initializer())"
        }, 
        {
            "source": "* ***Learning \uc218\ud589***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 Cost -- 62547.3 -- Prediction: -- [-75.96344757 -78.27629089 -83.83014679 -90.80435944 -56.97648239]\n100 Cost -- 13.2472 -- Prediction: -- [ 146.06376648  188.31446838  178.98654175  195.37893677  146.31259155]\n200 Cost -- 12.5621 -- Prediction: -- [ 146.20278931  188.21931458  179.02929688  195.40849304  146.18890381]\n300 Cost -- 11.9133 -- Prediction: -- [ 146.33810425  188.12670898  179.07095337  195.43722534  146.068573  ]\n400 Cost -- 11.2986 -- Prediction: -- [ 146.4697876   188.0365448   179.11146545  195.46513367  145.95143127]\n500 Cost -- 10.7164 -- Prediction: -- [ 146.59799194  187.94880676  179.15092468  195.49229431  145.83746338]\n600 Cost -- 10.1648 -- Prediction: -- [ 146.72277832  187.86340332  179.18934631  195.51869202  145.7265625 ]\n700 Cost -- 9.64238 -- Prediction: -- [ 146.84425354  187.7802887   179.22674561  195.54437256  145.61865234]\n800 Cost -- 9.14744 -- Prediction: -- [ 146.96246338  187.69935608  179.26315308  195.56930542  145.51361084]\n900 Cost -- 8.6786 -- Prediction: -- [ 147.07757568  187.62060547  179.29858398  195.59356689  145.41145325]\n1000 Cost -- 8.23449 -- Prediction: -- [ 147.18959045  187.54394531  179.33308411  195.61715698  145.31201172]\n1100 Cost -- 7.81377 -- Prediction: -- [ 147.29864502  187.46932983  179.3666687   195.64007568  145.21525574]\n1200 Cost -- 7.41522 -- Prediction: -- [ 147.40480042  187.396698    179.39938354  195.66235352  145.12110901]\n1300 Cost -- 7.0377 -- Prediction: -- [ 147.50811768  187.32600403  179.43119812  195.684021    145.02949524]\n1400 Cost -- 6.68003 -- Prediction: -- [ 147.60870361  187.25717163  179.46218872  195.70504761  144.94033813]\n1500 Cost -- 6.34126 -- Prediction: -- [ 147.706604    187.19020081  179.49237061  195.72554016  144.85360718]\n1600 Cost -- 6.02031 -- Prediction: -- [ 147.8019104   187.125       179.52174377  195.74542236  144.76919556]\n1700 Cost -- 5.71629 -- Prediction: -- [ 147.89468384  187.06155396  179.55033875  195.76475525  144.6870575 ]\n1800 Cost -- 5.4283 -- Prediction: -- [ 147.98498535  186.99978638  179.57817078  195.78353882  144.60714722]\n1900 Cost -- 5.15548 -- Prediction: -- [ 148.07289124  186.93965149  179.6053009   195.80180359  144.52940369]\n2000 Cost -- 4.89701 -- Prediction: -- [ 148.15844727  186.88110352  179.63166809  195.8195343   144.45372009]\n2100 Cost -- 4.65219 -- Prediction: -- [ 148.24176025  186.82415771  179.65737915  195.83679199  144.38012695]\n2200 Cost -- 4.42025 -- Prediction: -- [ 148.32284546  186.76870728  179.68238831  195.85353088  144.30848694]\n2300 Cost -- 4.20051 -- Prediction: -- [ 148.40177917  186.71472168  179.70674133  195.86981201  144.23878479]\n2400 Cost -- 3.99237 -- Prediction: -- [ 148.47862244  186.66218567  179.73045349  195.88563538  144.17097473]\n2500 Cost -- 3.79517 -- Prediction: -- [ 148.55342102  186.61103821  179.75354004  195.90100098  144.10498047]\n2600 Cost -- 3.60836 -- Prediction: -- [ 148.62623596  186.56126404  179.77603149  195.91593933  144.04077148]\n2700 Cost -- 3.43138 -- Prediction: -- [ 148.6971283   186.51280212  179.7979126   195.93043518  143.978302  ]\n2800 Cost -- 3.26374 -- Prediction: -- [ 148.76612854  186.46563721  179.81922913  195.9445343   143.91752625]\n2900 Cost -- 3.10489 -- Prediction: -- [ 148.83331299  186.41970825  179.83998108  195.95822144  143.85839844]\n3000 Cost -- 2.95446 -- Prediction: -- [ 148.89868164  186.37501526  179.86018372  195.97151184  143.80085754]\n3100 Cost -- 2.8119 -- Prediction: -- [ 148.96235657  186.33149719  179.87985229  195.98442078  143.74488831]\n3200 Cost -- 2.67686 -- Prediction: -- [ 149.02432251  186.28916931  179.89900208  195.9969635   143.69041443]\n3300 Cost -- 2.54892 -- Prediction: -- [ 149.08465576  186.2479248   179.91764832  196.00915527  143.63743591]\n3400 Cost -- 2.42771 -- Prediction: -- [ 149.14338684  186.20779419  179.93580627  196.02098083  143.58587646]\n3500 Cost -- 2.31288 -- Prediction: -- [ 149.20057678  186.16874695  179.95350647  196.03248596  143.53572083]\n3600 Cost -- 2.2041 -- Prediction: -- [ 149.25622559  186.13070679  179.97073364  196.04364014  143.48692322]\n3700 Cost -- 2.10103 -- Prediction: -- [ 149.31040955  186.09368896  179.98748779  196.05445862  143.43943787]\n3800 Cost -- 2.00338 -- Prediction: -- [ 149.36317444  186.05766296  180.0038147   196.06497192  143.39324951]\n3900 Cost -- 1.91086 -- Prediction: -- [ 149.41453552  186.02258301  180.01972961  196.07518005  143.34831238]\n4000 Cost -- 1.82322 -- Prediction: -- [ 149.46453857  185.9884491   180.03521729  196.08509827  143.30461121]\n4100 Cost -- 1.74017 -- Prediction: -- [ 149.51321411  185.9552002   180.05029297  196.09472656  143.26208496]\n4200 Cost -- 1.66149 -- Prediction: -- [ 149.56059265  185.9228363   180.06497192  196.10404968  143.22068787]\n4300 Cost -- 1.58694 -- Prediction: -- [ 149.60675049  185.89135742  180.07928467  196.11312866  143.18045044]\n4400 Cost -- 1.51631 -- Prediction: -- [ 149.65167236  185.86068726  180.09320068  196.12190247  143.14129639]\n4500 Cost -- 1.44939 -- Prediction: -- [ 149.69538879  185.83082581  180.10676575  196.13044739  143.10319519]\n4600 Cost -- 1.38598 -- Prediction: -- [ 149.73796082  185.80174255  180.1199646   196.13871765  143.06613159]\n4700 Cost -- 1.3259 -- Prediction: -- [ 149.7794342   185.77348328  180.13284302  196.14677429  143.03010559]\n4800 Cost -- 1.26897 -- Prediction: -- [ 149.81977844  185.74591064  180.14533997  196.15454102  142.99502563]\n4900 Cost -- 1.21504 -- Prediction: -- [ 149.85906982  185.71911621  180.15756226  196.16210938  142.96092224]\n5000 Cost -- 1.16392 -- Prediction: -- [ 149.89733887  185.69302368  180.16944885  196.16946411  142.92774963]\n"
                }
            ], 
            "source": "for step in range(5001):\n    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n    if step % 100 == 0:\n        print(step, \"Cost --\", cost_val, \"-- Prediction: --\", hy_val)\n"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}