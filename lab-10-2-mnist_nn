{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "---\n* *** \uc6d0\ubcf8 \uc18c\uc2a4\ub294 \ud64d\ucf69\uacfc\uae30\ub300 \uae40\uc131\ud6c8 \uad50\uc218\ub2d8\uc758  [Github link](https://github.com/hunkim/DeepLearningZeroToAll)\ub97c \ucc38\uc870\ud558\uc138\uc694 ***     \n* *** Watson studio notebook \uc5d0\uc11c \uc791\uc5c5 \uac00\ub2a5\ud558\ub3c4\ub85d \uc218\uc815\ud558\uc600\uc73c\uba70***\n* *** \ud55c\uae00\ub85c \uc124\uba85\ub41c \ubd80\ubd84\uc740 \uc81c\uac00 \uc2a4\ud130\ub514 \ud558\uba74\uc11c \uc774\ud574\ud55c \ub0b4\uc6a9\uc744 \ucd94\uac00\ud55c \uac83\uc785\ub2c8\ub2e4. ***\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "* ***Softmax \ub85c \ub3cc\ub9b0\uac83\uacfc  Neural Network \uc73c\ub85c \ub3cc\ub9b0 accuracy \uacb0\uacfc\ub97c \ube44\uad50\ud574\ubcf4\uae30 \uc704\ud574\uc11c  NN \uc73c\ub85c  ...... ***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Lab 10 MNIST and NN\nimport tensorflow as tf\nimport random\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.examples.tutorials.mnist import input_data\n\ntf.set_random_seed(777)  # reproducibility\n\n# parameters\nlearning_rate = 0.001\ntraining_epochs = 15\nbatch_size = 100\n\n# input place holders\nX = tf.placeholder(tf.float32, [None, 784])\nY = tf.placeholder(tf.float32, [None, 10])"
        }, 
        {
            "source": "* *** sigmoid \ub300\uc2e0\uc5d0 relu \uc0ac\uc6a9\ud569\ub2c8\ub2e4.***\n* *** relu\ub97c \uc0ac\uc6a9\ud558\ub294 \uc774\uc720\ub294  2-3 layer \uae4c\uc9c0\ub294 \ubb38\uc81c\uac00 \uc5c6\uc5c8\uc73c\ub098, layer \uac00 \uae4a\uc5b4\uc9c8\uc218\ub85d sigmoid \ud568\uc218\uac00 vanishing \ud6a8\uacfc\ub97c \ub098\ud0c0\ub0b4\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. ***\n* *** \uc989, 1 \ubcf4\ub2e4 \uc791\uc740 \uac12\uc744 \uacc4\uc18d \uacf1\ud568\uc73c\ub85c\uc368  back propagation \uc0ac\uc6a9\uc2dc \ucd08\uae30 input \uac12\uc5d0 \ub300\ud55c output \uc601\ud5a5\ub3c4\ub97c \ud310\ub2e8\ud560 \uc218 \uc5c6\uac8c \ub429\ub2c8\ub2e4. ***\n![#1](https://github.com/moreal70/TensorFlow-Lab-with-Watson-Studio/raw/master/images/sigmoid%20vs%20relu.png)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# weights & bias for nn layers\nW1 = tf.Variable(tf.random_normal([784, 256]))\nb1 = tf.Variable(tf.random_normal([256]))\nL1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n\nW2 = tf.Variable(tf.random_normal([256, 256]))\nb2 = tf.Variable(tf.random_normal([256]))\nL2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n\nW3 = tf.Variable(tf.random_normal([256, 10]))\nb3 = tf.Variable(tf.random_normal([10]))\nhypothesis = tf.matmul(L2, W3) + b3"
        }, 
        {
            "source": "* ***gradientdescent \ub300\uc2e0\uc5d0 AdamOptimizer \uc0ac\uc6a9\ud568***  \n* *** optimizer \uc131\ub2a5 \ube44\uad50 \ucc38\uace0 ***   \nhttp://www.denizyuret.com/2015/03/alec-radfords-animations-for.html    \nhttps://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "WARNING:tensorflow:From <ipython-input-6-15b6f115b9f0>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee tf.nn.softmax_cross_entropy_with_logits_v2.\n\nExtracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\nEpoch: 0001 cost = 145.001483716\nEpoch: 0002 cost = 40.839326976\nEpoch: 0003 cost = 25.852572872\nEpoch: 0004 cost = 18.058148869\nEpoch: 0005 cost = 13.026044874\nEpoch: 0006 cost = 9.573221398\nEpoch: 0007 cost = 7.279670635\nEpoch: 0008 cost = 5.405389653\nEpoch: 0009 cost = 4.061554504\nEpoch: 0010 cost = 3.002683313\nEpoch: 0011 cost = 2.291923197\nEpoch: 0012 cost = 1.712050864\nEpoch: 0013 cost = 1.378928077\nEpoch: 0014 cost = 1.116003549\nEpoch: 0015 cost = 0.871279964\nLearning Finished!\n"
                }
            ], 
            "source": "# define cost/loss & optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# initialize\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n# more information about the mnist dataset\n\n# train my model\nfor epoch in range(training_epochs):\n    avg_cost = 0\n    total_batch = int(mnist.train.num_examples / batch_size)\n\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        feed_dict = {X: batch_xs, Y: batch_ys}\n        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n        avg_cost += c / total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n\nprint('Learning Finished!')"
        }, 
        {
            "source": "* ***\uc55e\uc5d0 lab \uc5d0\uc11c softmax \ub294 90% \uc815\ub3c4\uc758 \uc815\ud655\ub3c4\ub97c \ubcf4\uc5ec\uc8fc\uc5c8\uc2b5\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Accuracy: 0.9443\n"
                }
            ], 
            "source": "# Test model and check accuracy\ncorrect_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nprint('Accuracy:', sess.run(accuracy, feed_dict={\n      X: mnist.test.images, Y: mnist.test.labels}))"
        }, 
        {
            "source": "* ***sample \uc744 random \ud558\uac8c \uac00\uc838\uc640\uc11c \uadf8\ub9bc\uc73c\ub85c \ubcf4\uc5ec\uc8fc\uace0 \uc608\uce21\ud569\ub2c8\ub2e4. ***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 53, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Label:  [7]\nPrediction:  [7]\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x222a24ad668>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "# Get one and predict\nr = random.randint(0, mnist.test.num_examples - 1)\nprint(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\nprint(\"Prediction: \", sess.run(\n    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n\nplt.imshow(mnist.test.images[r:r + 1].\n    reshape(28, 28), cmap='Greys', interpolation='nearest')\nplt.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "'''\nEpoch: 0001 cost = 141.207671860\nEpoch: 0002 cost = 38.788445864\nEpoch: 0003 cost = 23.977515479\nEpoch: 0004 cost = 16.315132428\nEpoch: 0005 cost = 11.702554882\nEpoch: 0006 cost = 8.573139748\nEpoch: 0007 cost = 6.370995680\nEpoch: 0008 cost = 4.537178684\nEpoch: 0009 cost = 3.216900532\nEpoch: 0010 cost = 2.329708954\nEpoch: 0011 cost = 1.715552875\nEpoch: 0012 cost = 1.189857912\nEpoch: 0013 cost = 0.820965160\nEpoch: 0014 cost = 0.624131458\nEpoch: 0015 cost = 0.454633765\nLearning Finished!\nAccuracy: 0.9455\n'''"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}