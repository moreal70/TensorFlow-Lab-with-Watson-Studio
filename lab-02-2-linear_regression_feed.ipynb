{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* *** 원본 소스는 홍콩과기대 김성훈 교수님의  [Github link](https://github.com/hunkim/DeepLearningZeroToAll)를 참조하세요 ***     \n",
    "* *** Watson studio notebook 에서 작업 가능하도록 수정하고 제가 study 하면서 이해한 내용을 첨언하였습니다.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab-02-2 linear regression feed\n",
    "\n",
    "* ***바로 앞에 Lab 2-1 하고 처리하는 로직은 동일합니다 ***\n",
    "* ***단, placeholder 라는 함수를 사용해서  input value 를 변수처리를 하도록 했고 ***\n",
    "* ***앞에서 얘기했듯이 이제 예측을 한번 해보는 겁니다.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HyeonSuPARK\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reprducibilty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***W,b 에 이름을 부여하고, 시작 값을 random으로 생성합니다.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to find value for W and b to compute y_data = x_data * W + b  \n",
    "# We know that W should be 1 and b should be 0\n",
    "# But let's TensorFlow figure it out \n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***값이 어떻게 들어올지 모르니, 행렬의 크기를 None, 즉 모른다로 정의합니다.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now we can use X and Y in place of x_data and y_data\n",
    "#### placeholders for a tensor that will be always fed using feed_dict\n",
    "#### See http://stackoverflow.com/questions/36693740/\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***앞에 Lab2-1과 동일합니다.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Lab2-1과 동일하지만, run 할때 training data를 받습니다.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.5240757 [2.1286771] [-0.8523567]\n",
      "200 0.07030439 [1.3072149] [-0.6983712]\n",
      "400 0.026845641 [1.18984] [-0.4315508]\n",
      "600 0.010250964 [1.1173096] [-0.26667204]\n",
      "800 0.003914324 [1.0724902] [-0.16478711]\n",
      "1000 0.0014946823 [1.0447946] [-0.10182849]\n",
      "1200 0.0005707396 [1.0276802] [-0.06292368]\n",
      "1400 0.00021793543 [1.0171047] [-0.03888312]\n",
      "1600 8.322027e-05 [1.0105698] [-0.02402747]\n",
      "1800 3.1776715e-05 [1.0065314] [-0.01484741]\n",
      "2000 1.21343355e-05 [1.0040361] [-0.00917497]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ =  sess.run([cost, W, b, train], feed_dict={X: [1, 2, 3], Y: [1, 2, 3]})\n",
    "    if step % 200 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 결과는 1,0 으로 수렴하지요. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  자 ! 이제 우리의 모델을 가지고 시험(예측)을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0110054]\n",
      "[2.500915]\n",
      "[1.4968792 3.5049512]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***주어진 x 값과 동일한 y 값이 나와야지요***\n",
    "* ***여기서 오해하면 안되는 것이,,, W,b 가 근사치로 정해졌기 때문에  예측치도 정확하게 일치 하지는 않습니다.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자 ! 이제 새로운 training 데이터를 가지고, 손쉽게  새로운 모델을 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.5203167e-07 [1.000325] [1.0988272]\n",
      "200 6.5212554e-08 [1.0001651] [1.0994035]\n",
      "400 1.6849981e-08 [1.000084] [1.0996966]\n",
      "600 4.380945e-09 [1.0000429] [1.0998453]\n",
      "800 1.1582415e-09 [1.0000219] [1.0999204]\n",
      "1000 3.2878233e-10 [1.0000118] [1.0999575]\n",
      "1200 7.504468e-11 [1.0000058] [1.0999795]\n",
      "1400 7.504468e-11 [1.0000058] [1.0999795]\n",
      "1600 7.504468e-11 [1.0000058] [1.0999795]\n",
      "1800 7.504468e-11 [1.0000058] [1.0999795]\n",
      "2000 7.504468e-11 [1.0000058] [1.0999795]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "                 feed_dict={X: [1, 2, 3, 4, 5],\n",
    "                            Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 200 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***새로운 W,b가 구해졌나요 ? ***\n",
    "* ***다시 테스트 (예측) 해봅시다.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1000085]\n",
      "[3.5999942]\n",
      "[2.5999885 4.6      ]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지금 두개의 모델을 만들었습니다.  만약 이 모델을  저장, 관리하면서 다른 사용자들에게 공유하고 싶다면 ?\n",
    "** [IBM CLoud site](https://console.bluemix.net/catalog/services/machine-learning) 에서 Watson machine learning 서비스를 활용하시면 됩니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
