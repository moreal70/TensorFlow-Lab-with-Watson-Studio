{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "---\n* *** \uc6d0\ubcf8 \uc18c\uc2a4\ub294 \ud64d\ucf69\uacfc\uae30\ub300 \uae40\uc131\ud6c8 \uad50\uc218\ub2d8\uc758  [Github link](https://github.com/hunkim/DeepLearningZeroToAll)\ub97c \ucc38\uc870\ud558\uc138\uc694 ***     \n* *** Watson studio notebook \uc5d0\uc11c \uc791\uc5c5 \uac00\ub2a5\ud558\ub3c4\ub85d \uc218\uc815\ud558\uc600\uc73c\uba70***\n* *** \ud55c\uae00\ub85c \uc124\uba85\ub41c \ubd80\ubd84\uc740 \uc81c\uac00 \uc2a4\ud130\ub514 \ud558\uba74\uc11c \uc774\ud574\ud55c \ub0b4\uc6a9\uc744 \ucd94\uac00\ud55c \uac83\uc785\ub2c8\ub2e4. ***\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Lab-03-3 Minimizing Cost TF Optimizer\n* ***\uc55e\uc11c\uc11c\ub294 W \uac12\uc744 random \uc73c\ub85c \uc2dc\uc791\ud587\uc2b5\ub2c8\ub2e4\ub9cc \uc5ec\uae30\uc11c\ub294 \ud2b9\uc815\uac12\uc73c\ub85c \uc2dc\uc791\ud569\ub2c8\ub2e4.***\n* ***\ub2e4\ub978 \uac12\uc73c\ub85c \uc5ec\ub7ec\ubc88 \ub3cc\ub824\ubcf4\uba74, W \uac12\uc774 \ucd5c\uc885 \uc218\ub834\uac12\uc73c\ub85c \ub3c4\ub2ec\ud558\uae30 \uae4c\uc9c0 \uc5b4\ub5bb\uac8c \ubcc0\ud654\ud558\ub294 \uc9c0 \uc774\ud574\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.***\n* ***\uacbd\uc0ac\ud558\uac15\ubc95\uc5d0\uc11c \uc5b4\ub5bb\uac8c \ud558\uac15\ud558\ub294\uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import tensorflow as tf\ntf.set_random_seed(777)  # for reproducibility"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# tf Graph Input\nX = [1, 2, 3]\nY = [1, 2, 3]"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Set wrong model weights\nW = tf.Variable(-5.0)"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Linear model\nhypothesis = X * W\n\n# cost/loss function\ncost = tf.reduce_mean(tf.square(hypothesis - Y))"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Minimize: Gradient Descent Magic\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\ntrain = optimizer.minimize(cost)"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Launch the graph in a session.\nsess = tf.Session()\n# Initializes global variables in the graph.\nsess.run(tf.global_variables_initializer())"
        }, 
        {
            "source": "* ***Learning***", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0 -5.0\n1 0.6\n2 0.973333\n3 0.998222\n4 0.999882\n5 0.999992\n6 0.999999\n7 1.0\n8 1.0\n9 1.0\n10 1.0\n11 1.0\n12 1.0\n13 1.0\n14 1.0\n15 1.0\n16 1.0\n17 1.0\n18 1.0\n19 1.0\n20 1.0\n21 1.0\n22 1.0\n23 1.0\n24 1.0\n25 1.0\n26 1.0\n27 1.0\n28 1.0\n29 1.0\n30 1.0\n31 1.0\n32 1.0\n33 1.0\n34 1.0\n35 1.0\n36 1.0\n37 1.0\n38 1.0\n39 1.0\n40 1.0\n41 1.0\n42 1.0\n43 1.0\n44 1.0\n45 1.0\n46 1.0\n47 1.0\n48 1.0\n49 1.0\n50 1.0\n51 1.0\n52 1.0\n53 1.0\n54 1.0\n55 1.0\n56 1.0\n57 1.0\n58 1.0\n59 1.0\n60 1.0\n61 1.0\n62 1.0\n63 1.0\n64 1.0\n65 1.0\n66 1.0\n67 1.0\n68 1.0\n69 1.0\n70 1.0\n71 1.0\n72 1.0\n73 1.0\n74 1.0\n75 1.0\n76 1.0\n77 1.0\n78 1.0\n79 1.0\n80 1.0\n81 1.0\n82 1.0\n83 1.0\n84 1.0\n85 1.0\n86 1.0\n87 1.0\n88 1.0\n89 1.0\n90 1.0\n91 1.0\n92 1.0\n93 1.0\n94 1.0\n95 1.0\n96 1.0\n97 1.0\n98 1.0\n99 1.0\n"
                }
            ], 
            "source": "for step in range(100):\n    print(step, sess.run(W))\n    sess.run(train)"
        }, 
        {
            "source": "* ***\ucc98\uc74c\uc5d0 \uc9c0\uc815\ud55c W\uac12\uc5d0\uc11c \uc2dc\uc791\ud574\uc11c \uc5b4\ub5bb\uac8c \ubcc0\ud654\ub418\uc5c8\ub098\uc694 ? *** \n* ***learning rate \uac12\uc744 \ub354 \uc791\uac8c \ubc14\uafb8\uc5b4 \ubcf4\uc138\uc694 ***", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}